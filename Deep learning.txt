from google.colab import drive
drive.mount('/content/drive')

import ee
ee.Authenticate()
ee.Initialize()

import tensorflow as tf
import folium
from tensorflow import keras

# Your Earth Engine username.  This is used to import a classified image
# into your Earth Engine assets folder.
USER_NAME = '20656YJX'
# Use Landsat 8 surface reflectance data for predictors.
# Cloud masking function.
def maskS2clouds(image):
  qa = image.select('QA60')

  # Bits 10 and 11 are clouds and cirrus, respectively.
  cloudBitMask = 1 << 10
  cirrusBitMask = 1 << 11

  # Both flags should be set to zero, indicating clear conditions.
  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(
             qa.bitwiseAnd(cirrusBitMask).eq(0))

  # Return the masked and scaled data, without the QA bands.
  return image.updateMask(mask).divide(10000) \
      .select("B.*") \
      .copyProperties(image, ["system:time_start"])
def addIndices(image):
  ndvi = image.normalizedDifference(['B8', 'B4']).rename(['ndvi'])
  ndvire2 = image.normalizedDifference(['B8A', 'B6']).rename(['ndvire2'])
  return image.addBands(ndvi.rename("NDVI")).addBands(ndvire2.rename("NDVIRE2"))
# The image input data is a 2018 cloud-masked median composite.
S2 = ee.ImageCollection('COPERNICUS/S2').filterDate('2021-07-01', '2021-08-31').map(maskS2clouds).map(addIndices).median()
# S22 = ee.ImageCollection('COPERNICUS/S2').filterDate('2021-07-22', '2021-08-31').map(maskS2clouds).median()
collection_S1=ee.ImageCollection('COPERNICUS/S1_GRD') \
.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \
.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))
collection_S1_IW=collection_S1 \
.filterMetadata('instrumentMode','equals','IW') \
.filterDate('2021-07-01', '2021-08-31')
Sentinel_1=collection_S1_IW.median()
# collection_S11=ee.ImageCollection('COPERNICUS/S1_GRD') \
# .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \
# .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))
# collection_S1_IW1=collection_S11 \
# .filterMetadata('instrumentMode','equals','IW') \
# .filterDate('2021-07-22', '2021-08-31')

# Sentinel_11=collection_S1_IW1.median()
image = ee.Image.cat([Sentinel_1,S2]).float()
from pprint import pprint
# pprint(image.getInfo())

# Use these bands for prediction.
BANDS = ['B8','B4','VV','B3','NDVIRE2','VH','NDVI','B1','B6','B7','B2','B12',]

# This is a trianing/testing dataset of points with known land cover labels.
LABEL_DATA = ee.FeatureCollection('users/20656YJX/YBPoints1')
        
# The labels, consecutive integer indices starting from zero, are stored in
# this property, set on each point.
LABEL = 'landcover'
# Number of label values, i.e. number of classes in the classification.
N_CLASSES = 4

# These names are used to specify properties in the export of
# training/testing data and to define the mapping between names and data
# when reading into TensorFlow datasets.
FEATURE_NAMES = list(BANDS)
FEATURE_NAMES.append(LABEL)

# File names for the training and testing datasets.  These TFRecord files
# will be exported from Earth Engine into the Cloud Storage bucket.
TRAIN_FILE_PREFIX = 'Training_demo'
TEST_FILE_PREFIX = 'Testing_demo'
file_extension = '.tfrecord.gz'
TRAIN_FILE_PATH = r'/content/drive/MyDrive/RS2STUDYAREA2'
TEST_FILE_PATH = r'/content/drive/MyDrive/RS2STUDYAREA2'

# File name for the prediction (image) dataset.  The trained model will read
# this dataset and make predictions in each pixel.
IMAGE_FILE_PREFIX = 'Image_pixel_demo_'

# The output path for the classified image (i.e. predictions) TFRecord file.
OUTPUT_IMAGE_FILE = r'/content/drive/MyDrive/RS2STUDYAREA2/Classified_pixel_demo.TFRecord'
# Export imagery in this region.
EXPORT_REGION = ee.Geometry.Polygon(
        [[[97.75951502015543, 36.07885552317394],
          [97.75951502015543, 36.03734457776351],
          [97.80537006547404, 36.03734457776351],
          [97.80537006547404, 36.07885552317394]]])

# The name of the Earth Engine asset to be created by importing
# the classified image from the TFRecord file in Cloud Storage.
OUTPUT_ASSET_ID = 'users/' + USER_NAME + '/Classified_pixel_demo'

image2 = image.clip(EXPORT_REGION)
# Use folium to visualize the imagery.
mapid = image2.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})
map = folium.Map(location=[37.539295218085485,101.54934612154766])
folium.TileLayer(
    tiles=mapid['tile_fetcher'].url_format,
    attr='Map Data &copy; <a href="https://earthengine.google.com/">Google Earth Engine</a>',
    overlay=True,
    name='median composite',
  ).add_to(map)
map.add_child(folium.LayerControl())
map

# Sample the image at the points and add a random column.
sample = image2.sampleRegions(
  collection=LABEL_DATA, properties=[LABEL], scale=10).randomColumn()

# Partition the sample approximately 70-30.
training = sample.filter(ee.Filter.lt('random', 0.7))
testing = sample.filter(ee.Filter.gte('random', 0.7))

from pprint import pprint
# pprint(testing.getInfo())

# Create the tasks.
training_task = ee.batch.Export.table.toDrive(
  collection=training,
  description='Training Export',
  fileNamePrefix=TRAIN_FILE_PREFIX,
  folder='RS2STUDYAREA2',
  fileFormat='TFRecord',
  selectors=FEATURE_NAMES)

testing_task = ee.batch.Export.table.toDrive(
  collection=testing,
  description='Testing Export',
  fileNamePrefix=TEST_FILE_PREFIX,
  folder='RS2STUDYAREA2',
  fileFormat='TFRecord',
  selectors=FEATURE_NAMES)

# Start the tasks.
training_task.start()
testing_task.start()

# Specify patch and file dimensions.
image_export_options = {
  'patchDimensions': [256, 256],
  'maxFileSize': 104857600,
  'compressed': True
}

# Setup the task.
image_task = ee.batch.Export.image.toDrive(
  image=image,
  description='Image Export',
  fileNamePrefix=IMAGE_FILE_PREFIX,
  folder='RS2STUDYAREA2',
  scale=10,
  fileFormat='TFRecord',
  region=EXPORT_REGION.toGeoJSON()['coordinates'],
  formatOptions=image_export_options,
)

# Start the task.
image_task.start()


# Create a dataset from the TFRecord file in Cloud Storage.
train_dataset = tf.data.TFRecordDataset(r'/content/drive/MyDrive/RS2STUDYAREA2/Training_demo.tfrecord.gz', compression_type='GZIP')
# Print the first record to check.
print(iter(train_dataset).next())


# List of fixed-length features, all of which are float32.
columns = [
  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES
]

# Dictionary with names as keys, features as values.
features_dict = dict(zip(FEATURE_NAMES, columns))
pprint(features_dict)


def parse_tfrecord(example_proto):
  """The parsing function.

  Read a serialized example into the structure defined by featuresDict.

  Args:
    example_proto: a serialized Example.

  Returns:
    A tuple of the predictors dictionary and the label, cast to an `int32`.
  """
  parsed_features = tf.io.parse_single_example(example_proto, features_dict)
  labels = parsed_features.pop(LABEL)
  return parsed_features, tf.cast(labels, tf.int32)
# Map the function over the dataset.
parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)

# Print the first parsed record to check.
pprint(iter(parsed_dataset).next())

from tensorflow import keras

# Add NDVI.
input_dataset = parsed_dataset

# Keras requires inputs as a tuple.  Note that the inputs must be in the
# right shape.  Also note that to use the categorical_crossentropy loss,
# the label needs to be turned into a one-hot vector.
def to_tuple(inputs, label):
  return (tf.transpose(list(inputs.values())),
          tf.one_hot(indices=label, depth=N_CLASSES))

# Map the to_tuple function, shuffle and batch.
input_dataset = input_dataset.map(to_tuple).batch(64)
# Define the layers in the model.
model = tf.keras.models.Sequential([
  tf.keras.layers.Dense(64, activation=tf.nn.relu),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(32, activation=tf.nn.relu),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(16, activation=tf.nn.relu),
  tf.keras.layers.Dropout(0.2),


  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)
])
from keras import metrics


# Compile the model with the specified loss function.
model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall()])

# Fit the model to the training data.
history = model.fit(x=input_dataset, epochs=5000)

import matplotlib as mpl
import matplotlib.pyplot as plt
%matplotlib inline
import pandas as pd
def plot_learning_curves(history):
    pd.DataFrame(history.history).plot(figsize = (8, 5))
    plt.grid(True)
    plt.gca().set_ylim(0, 1)
    plt.show()

plot_learning_curves(history)

model.save("/content/drive/MyDrive/RS2STUDYAREA2/MyModelS2")

reconstructed_model = keras.models.load_model("/content/drive/MyDrive/RS2STUDYAREA2/MyModelS2") #Model tranfer
test_dataset = (
  tf.data.TFRecordDataset(r'/content/drive/MyDrive/RS2STUDYAREA2/Testing_demo.tfrecord.gz', compression_type='GZIP')
    .map(parse_tfrecord, num_parallel_calls=5)
    .map(to_tuple)
    .batch(1))
model.evaluate(test_dataset)

import os
import json
# Get a list of all the files in the tfrecord data folder.
os.chdir(r'/content/drive/MyDrive/RS2STUDYAREA2')
filesList = !ls -1 
PredFilesList = [s for s in filesList if IMAGE_FILE_PREFIX in s]
# Get the list of image files and the JSON mixer file.
image_files_list = []
jsonFile = None
for f in PredFilesList:
    if f.endswith('.tfrecord.gz'):
        image_files_list.append(f)
    elif f.endswith('.json'):
        jsonFile = f
image_files_list.sort()


# Load the contents of the mixer file to a JSON object,and obtain the number of patches
jsonText = !cat {jsonFile}
mixer = json.loads(jsonText.nlstr)
patches = mixer['totalPatches']
mixer

# Get relevant info from the JSON mixer file.
patch_width = mixer['patchDimensions'][0]
patch_height = mixer['patchDimensions'][1]
patches = mixer['totalPatches']
patch_dimensions_flat = [patch_width * patch_height, 1]

# Note that the tensors are in the shape of a patch, one patch for each band.
image_columns = [
  tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) 
    for k in BANDS
]

# Parsing dictionary.
image_features_dict = dict(zip(BANDS, image_columns))

# Note that you can make one dataset from many files by specifying a list.
image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')

# Parsing function.
def parse_image(example_proto):
  return tf.io.parse_single_example(example_proto, image_features_dict)

# Parse the data into tensors, one long tensor per patch.
image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)

# Break our long tensors into many little ones.
image_dataset = image_dataset.flat_map(
  lambda features: tf.data.Dataset.from_tensor_slices(features)
)

# # Add additional features (NDVI).
# image_dataset = image_dataset.map(
#   # Add NDVI to a feature that doesn't have a label.
#   lambda features: add_NDVI(features, None)[0]
# ).map(
#   # Add NDVIRE1 to a feature that doesn't have a label.
#   lambda features: add_NDVIRE2(features, None)[0]
# )

# Turn the dictionary in each record into a tuple without a label.
image_dataset = image_dataset.map(
  lambda data_dict: (tf.transpose(list(data_dict.values())), )
)

# Turn each patch into a batch.
image_dataset = image_dataset.batch(patch_width * patch_height)

# Run prediction in batches, with as many steps as there are patches.
predictions = reconstructed_model.predict(image_dataset, steps=patches, verbose=1)

# Note that the predictions come as a numpy array.  Check the first one.
print(predictions[0])

print('Writing to file ' + OUTPUT_IMAGE_FILE)

# Instantiate the writer.
writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)

# Every patch-worth of predictions we'll dump an example into the output
# file with a single feature that holds our predictions. Since our predictions
# are already in the order of the exported data, the patches we create here
# will also be in the right order.
patch = [[], [], [], [], []]
cur_patch = 1
for prediction in predictions:
  patch[0].append(tf.argmax(prediction, 1))
  patch[1].append(prediction[0][0])
  patch[2].append(prediction[0][1])
  patch[3].append(prediction[0][2])
  patch[4].append(prediction[0][3])
  # Once we've seen a patches-worth of class_ids...
  if (len(patch[0]) == patch_width * patch_height):
    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')
    # Create an example
    example = tf.train.Example(
      features=tf.train.Features(
        feature={
          'prediction': tf.train.Feature(
              int64_list=tf.train.Int64List(
                  value=patch[0])),
          'XM': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[1])),
          'YC': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[2])),
          'LM': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[3])),
          'QT': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[4])),
        }
      )
    )
    # Write the example to the file and clear our patch array so it's ready for
    # another batch of class ids
    writer.write(example.SerializeToString())
    patch = [[], [], [], [], []]
    cur_patch += 1

writer.close()

print('Uploading to ' + OUTPUT_ASSET_ID)